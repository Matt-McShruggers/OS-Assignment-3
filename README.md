# üñ•Ô∏è Asignaci√≥n No. 3: Ambiente de computaci√≥n distribuida üñ•Ô∏è

Este repositorio es un poco distinto al que se est√° acostumbrado. Esto se debe a que se trabajaron a lo largo de 3 m√°quinas virtuales, implementando un funcionamiento unido de los servicios Nginx, Apache, Docker-Compose y el framework Ray. Por ende, como la asignaci√≥n fue dividida entre las partes del funcionamiento entre los servicios y la prueba del framework, se pueden considerar que son divididas en las carpetas *"Network_Topology"* y *"Ray_Framework"*.

### << Parte 1: Network_Topology >> 
- Dentro de la carpeta se encontrar√°n 3 carpetas, cada una con el nombre de la m√°quina virtual correspondiente a la que se trabajaron los archivos internos de cada servicio. En el caso de NGINX y para Apache en las otras 2, se hicieron archivos de Virtual Host que permit√≠an configurar acordemente lo que se ped√≠a. Cada uno de estos archivos lleva el modelo de nombre "**[nombre del servicio].conf**". La habilitaci√≥n de estos se hace mediante una serie variada de comandos.
- En el caso de la m√°quina virtual de Docker-Compose, para levantar programas es necesario de un archivo **docker-compose.yml** y consecuentemente **Dockerfile**, los cuales sirven para establecer la configuraci√≥n deseada del programa. Para efectos de sencillez, el programa tiene el nombre de archivo **app.py**, y solo basta con estar en la carpeta y utilizar el comando `docker-compose up` en una instancia de la terminal (Tal como se muestra en el PDF) para activar la instancia de Docker-Compose.

### << Parte 2: Ray_Framework >>
Ray tiene la libertad de que puede correr en cualquier dispositivo que tenga soporte para Python 3.7 en adelante. La manera en la que funciona, es que permite la construcci√≥n de "clusters" de dispositivos, para as√≠ correr programas de Python escogiendo recursos distributivamente de los dispositivos conectados a este cluster. Entonces, vemos que el √∫nico archivo en esta carpeta es el programa en Python **programa_prueba.py**. Para utilizar el framework, se deben seguir los pasos:
1) Desde el dispositivo que va a ser el centro/la cabeza de nodos, ejecutar el comando `ray start --head` en una terminal iniciar√° el cluster. En nuestro caso, utilizamos la m√°quina virtual *sisoper-apache* para ser la cabeza. Luego, para cada dispositivo que des√©e unirse al cluster `ray start --address=[head_IP]:6379`, donde "*head_IP*" es la IP del dispositivo que se inicializ√≥ como la cabeza de nodos.
2) A√±adiendo lineas extras al programa escrito en Python es necesario para que Ray pueda ejecutarlo de manera distribuida. Para correrlo en este caso, es tan simple como ejecutar el comando `python3.7 programa_prueba.py` en la terminal.
